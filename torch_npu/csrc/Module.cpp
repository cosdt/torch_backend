#include <chrono>
#include <ATen/Parallel.h>
#include <Python.h>
#include <torch/csrc/utils.h>
#include <torch/csrc/profiler/python/combined_traceback.h>

#include "csrc/aten/generated/python_functions.h"
#include "csrc/npu/NPUGeneratorImpl.h"
#include "npu/adapter/acl_device_adapter.h"
#include "npu/core/NpuVariables.h"
#include "torch_npu/csrc/core/AutocastMode.h"
#include "torch_npu/csrc/core/TensorType.h"
#include "torch_npu/csrc/npu/Device.h"
#include "torch_npu/csrc/npu/Event.h"
#include "torch_npu/csrc/npu/Memory.h"
#include "torch_npu/csrc/npu/Stream.h"

PyObject* module;

static PyObject* THNPModule_initExtension(PyObject* self, PyObject* noargs) {
  HANDLE_TH_ERRORS {
    pybind11::gil_scoped_release no_gil;
    at::globalContext().lazyInitPrivateUse1();
  }
  auto m = THPObjectPtr(PyImport_ImportModule("torch.npu"));
  if (!m) {
    throw python_error();
  }

  auto set_module_attr = [&](const char* name, PyObject* v) {
    // PyObject_SetAttrString doesn't steal reference. So no need to incref.
    if (PyObject_SetAttrString(m, name, v) < 0) {
      throw python_error();
    }
  };
  c10::DeviceIndex num_npus = c10_npu::device_count();
  auto default_npu_generators = PyTuple_New(static_cast<Py_ssize_t>(num_npus));
  for (c10::DeviceIndex i = 0; i < num_npus; i++) {
    auto gen = at_npu::detail::getDefaultNPUGenerator(i);
    auto cast_gen = (THPGenerator*)THPGenerator_initDefaultGenerator(gen);
    // This reference is meant to be given away, so no need to incref here.
    PyTuple_SetItem(default_npu_generators, i, (PyObject*)cast_gen);
  }
  at_npu::autograd::generated::initialize_autogenerated_functions(m);
  set_module_attr("default_generators", default_npu_generators);

  Py_RETURN_NONE;
  END_HANDLE_TH_ERRORS
}

// We need to ensure that as long as a thread will NEVER loose the GIL as long
// as it holds the NPU mutex. Otherwise another thread might be scheduled and
// try to e.g. allocate a new tensor which will cause a deadlock. It's enough to
// have a single global, because it can be only set once (npuMutex is not
// recursive) by the thread that owns the mutex (obviously there can be only one
// such thread).
static PyGILState_STATE npuMutexGILState;

PyObject* THNPModule_npuLockMutex(PyObject* module, PyObject* noargs) {
  auto mutex = c10_npu::getFreeMutex();
  // This has to be a busy loop because we **absolutely need to** hold the GIL
  // or it's a recipe for a deadlock otherwise (if we let other Python threads
  // run while we have the cudaMutex, but not the GIL, they might try to e.g.
  // free a CUDA tensor and acquire the cudaMutex without giving up the GIL,
  // because it happens deep within THC).
  while (true) {
    if (mutex->try_lock()) {
      break;
    }
    {
      pybind11::gil_scoped_release no_gil;
      std::this_thread::sleep_for(std::chrono::microseconds(10));
    }
  }

  npuMutexGILState = PyGILState_Ensure();
  Py_RETURN_NONE;
}

PyObject* THNPModule_npuUnlockMutex(PyObject* module, PyObject* noargs) {
  auto mutex = c10_npu::getFreeMutex();
  PyGILState_Release(npuMutexGILState);
  mutex->unlock();
  Py_RETURN_NONE;
}

// NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays, modernize-avoid-c-arrays)
static PyMethodDef TorchNpuMethods[] = {
    {"_npu_init", (PyCFunction)THNPModule_initExtension, METH_NOARGS, nullptr},
    {"_npu_lock_mutex",
     (PyCFunction)THNPModule_npuLockMutex,
     METH_NOARGS,
     nullptr},
    {"_npu_unlock_mutex",
     (PyCFunction)THNPModule_npuUnlockMutex,
     METH_NOARGS,
     nullptr},
    {nullptr, nullptr, 0, nullptr}};

static std::vector<PyMethodDef> methods;

extern "C" C10_EXPORT PyObject* initModule();
PyObject* initModule() {
  at::internal::lazy_init_num_threads();

  THPUtils_addPyMethodDefs(methods, TorchNpuMethods);
  THPUtils_addPyMethodDefs(methods, THNPModule_device_methods());
  THPUtils_addPyMethodDefs(methods, THNPModule_memory_methods());
  THPUtils_addPyMethodDefs(methods, THNPModule_stream_methods());
  THPUtils_addPyMethodDefs(
      methods, torch_npu::utils::npu_extension_functions());
  THPUtils_addPyMethodDefs(
      methods, torch_npu::autocast::autocast_mode_functions());
  static struct PyModuleDef torchnpu_module = {
      PyModuleDef_HEAD_INIT, "torch_npu._C", nullptr, -1, methods.data()};
  module = PyModule_Create(&torchnpu_module);

  // This will only initialize base classes and attach them to library namespace
  // They won't be ready for real usage until importing npu module, that will
  // complete the process (but it defines Python classes before calling back
  // into C, so these lines have to execute first)..
  THNPStream_init(module);
  THNPEvent_init(module);

  RegisterNPUDeviceProperties(module);
  BindGetDeviceProperties(module);
  torch::installCapturedTracebackPython();
  return module;
}
